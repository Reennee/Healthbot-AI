{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Healthcare Chatbot Fine-tuning Pipeline\n",
        "\n",
        "This notebook demonstrates how to fine-tune a transformer model for healthcare domain-specific conversations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     AutoTokenizer, \n\u001b[32m      6\u001b[39m     AutoModelForCausalLM, \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     DataCollatorForLanguageModeling\n\u001b[32m     10\u001b[39m )\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForCausalLM, \n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing and Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load larger healthcare dataset from Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "try:\n",
        "    # Load healthcare chatbot dataset\n",
        "    health_dataset = load_dataset(\"shaneperry0101/health-chatbot\")\n",
        "    print(f\"Hugging Face dataset size: {len(health_dataset['train'])}\")\n",
        "    \n",
        "    # Convert to training format\n",
        "    hf_training_data = []\n",
        "    for example in health_dataset['train']:\n",
        "        # Apply same preprocessing as above\n",
        "        user_msg = ' '.join(example['input'].lower().split())\n",
        "        assistant_msg = ' '.join(example['output'].lower().split())\n",
        "        \n",
        "        user_msg = re.sub(r'[^\\w\\s\\.\\?\\!]', '', user_msg)\n",
        "        assistant_msg = re.sub(r'[^\\w\\s\\.\\?\\!]', '', assistant_msg)\n",
        "        \n",
        "        formatted_text = f\"<|startoftext|>Patient: {user_msg}<|endoftext|>Doctor: {assistant_msg}<|endoftext|>\"\n",
        "        hf_training_data.append({\"text\": formatted_text})\n",
        "    \n",
        "    print(f\"Created {len(hf_training_data)} training examples from Hugging Face\")\n",
        "    \n",
        "    # Use the larger dataset for training\n",
        "    training_data = hf_training_data\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Could not load Hugging Face dataset: {e}\")\n",
        "    print(\"Using custom dataset instead\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration - using GPT-2 for better healthcare performance\n",
        "MODEL_NAME = \"gpt2\"  # or \"gpt2-medium\" for better quality\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "# Load tokenizer with proper configuration\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Add special tokens for healthcare conversations\n",
        "special_tokens = {\n",
        "    \"additional_special_tokens\": [\"<|startoftext|>\", \"<|endoftext|>\", \"Patient:\", \"Doctor:\"]\n",
        "}\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "# Configure padding token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"Tokenizer loaded: {MODEL_NAME}\")\n",
        "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
        "print(f\"Special tokens added: {special_tokens['additional_special_tokens']}\")\n",
        "\n",
        "# Test tokenization\n",
        "sample_text = \"<|startoftext|>Patient: I have a headache<|endoftext|>Doctor:\"\n",
        "tokens = tokenizer.encode(sample_text)\n",
        "print(f\"Sample tokenization: {tokens}\")\n",
        "print(f\"Decoded: {tokenizer.decode(tokens)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
